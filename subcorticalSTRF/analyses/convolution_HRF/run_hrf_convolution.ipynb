{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1dd700",
   "metadata": {},
   "source": [
    "# HRF Convolution Pipeline for Cochlea and BEZ Models\n",
    "\n",
    "This notebook provides an interactive interface to run HRF convolution on PSTH data from both Cochlea and BEZ models.\n",
    "\n",
    "## Features\n",
    "- Load PSTH data from either or both models\n",
    "- **BEZ**: Process each simulation run separately (preserves run-to-run variability)\n",
    "- **Cochlea**: Single deterministic response per condition\n",
    "- Configure convolution parameters interactively\n",
    "- Visualize canonical HRF\n",
    "- Run convolution and inspect results\n",
    "- Save convolved responses for later analysis\n",
    "- Compare model outputs\n",
    "\n",
    "## Workflow\n",
    "1. Set up environment and parameters\n",
    "2. Load model data\n",
    "3. Generate and visualize canonical HRF\n",
    "4. Run convolution\n",
    "5. Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db5ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/ekim/PycharmProjects/phd_firstyear/subcorticalSTRF/convolution_HRF\n",
      "✓ All modules imported successfully\n",
      "\n",
      "Important: BEZ model uses per-run convolution to preserve variability\n",
      "✓ All modules imported successfully\n",
      "\n",
      "Important: BEZ model uses per-run convolution to preserve variability\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set working directory\n",
    "notebook_dir = Path.cwd()\n",
    "if notebook_dir.name != 'convolution_HRF':\n",
    "    convolution_hrf_dir = (\n",
    "        notebook_dir / 'convolution_HRF' \n",
    "        if (notebook_dir / 'convolution_HRF').exists() \n",
    "        else notebook_dir.parent / 'convolution_HRF'\n",
    "    )\n",
    "    os.chdir(convolution_hrf_dir)\n",
    "    print(f\"Changed working directory to: {convolution_hrf_dir}\")\n",
    "else:\n",
    "    print(f\"Working directory: {notebook_dir}\")\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import convolution functions\n",
    "# For Cochlea - uses standard method\n",
    "from convolutionHRF_draft_221025 import (\n",
    "    load_cochlea_psth_data,\n",
    "    convolve_cochlea_with_hrf,\n",
    "    plot_convolved_responses,\n",
    "    subset_parameters\n",
    ")\n",
    "\n",
    "# For BEZ - uses per-run convolution method\n",
    "from convolutionHRF_bez_eachrun_231025 import (\n",
    "    load_bez_psth_data,\n",
    "    convolve_bez_runs_with_hrf,\n",
    "    plot_convolved_runs,\n",
    "    plot_runs_comparison_across_cfs\n",
    ")\n",
    "\n",
    "# Utility functions\n",
    "from convolution_utils import (\n",
    "    generate_canonical_hrf,\n",
    "    plot_hrf,\n",
    "    generate_timestamp,\n",
    "    save_convolved_data\n",
    ")\n",
    "\n",
    "print(\"✓ All modules imported successfully\")\n",
    "print(\"\\nImportant: BEZ model uses per-run convolution to preserve variability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a915fcc",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "Set parameters for the convolution analysis. You can modify these settings as needed.\n",
    "\n",
    "**Note on BEZ Model:** Each simulation run is convolved separately to preserve run-to-run variability, which is important for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e5aff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuration Summary ===\n",
      "Model: both\n",
      "TR: 0.1s (sampling rate: 10 Hz)\n",
      "HRF length: 32.0s\n",
      "Fiber types: ['hsr', 'msr', 'lsr']\n",
      "Test mode: True\n",
      "Output directory: results\n",
      "Save plots: True\n",
      "Save data: True\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION PARAMETERS ===\n",
    "\n",
    "# Model selection\n",
    "MODEL = 'both'  # Options: 'cochlea', 'bez', 'both'\n",
    "\n",
    "# HRF parameters\n",
    "TR = 0.1  # Temporal resolution in seconds (100 Hz sampling)\n",
    "HRF_LENGTH = 32.0  # HRF duration in seconds\n",
    "\n",
    "# Fiber types to process\n",
    "FIBER_TYPES = ['hsr', 'msr', 'lsr']  # All fiber types\n",
    "\n",
    "# Data subset parameters (set to None to process all)\n",
    "MAX_CFS = None  # Maximum number of CFs to process\n",
    "MAX_FREQS = None  # Maximum number of frequencies\n",
    "MAX_DBS = None  # Maximum number of dB levels\n",
    "\n",
    "# Test mode (process only small subset for quick testing)\n",
    "TEST_MODE = True  # Set to True for quick testing\n",
    "\n",
    "# Plotting parameters\n",
    "DB_LEVEL_TO_PLOT = 60.0  # dB level for visualization\n",
    "PLOT_FORMAT = 'png'  # Options: 'png', 'pdf', 'svg'\n",
    "\n",
    "# Output settings\n",
    "OUTPUT_DIR = 'results'\n",
    "SAVE_PLOTS = True\n",
    "SAVE_DATA = True\n",
    "\n",
    "# Display configuration\n",
    "print(\"=== Configuration Summary ===\")\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"TR: {TR}s (sampling rate: {1/TR:.0f} Hz)\")\n",
    "print(f\"HRF length: {HRF_LENGTH}s\")\n",
    "print(f\"Fiber types: {FIBER_TYPES}\")\n",
    "print(f\"Test mode: {TEST_MODE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Save plots: {SAVE_PLOTS}\")\n",
    "print(f\"Save data: {SAVE_DATA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1def2",
   "metadata": {},
   "source": [
    "## Step 2: Load Model Data\n",
    "\n",
    "Load PSTH data from the selected model(s).\n",
    "\n",
    "**Data Structure:**\n",
    "- **Cochlea**: Single response per condition `[fiber_type][CF][frequency][dB]`\n",
    "- **BEZ**: Multiple runs per condition `[fiber_type][CF][frequency][dB][run_idx]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33357f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading BOTH Model Data ===\n",
      "\n",
      "Loading Cochlea data...\n",
      "Loading cochlea PSTH data from: /home/ekim/PycharmProjects/phd_firstyear/subcorticalSTRF/cochlea_meanrate/out/condition_psths/cochlea_psths.mat\n",
      "✓ Cochlea PSTH data loaded successfully\n",
      "Parameters extracted:\n",
      "  CFs: 20 values\n",
      "  Frequencies: 20 values\n",
      "  dB levels: [50. 60. 70. 80.]\n",
      "\n",
      "Loading BEZ data...\n",
      "Loading BEZ PSTH data from: //subcorticalSTRF/BEZ2018_meanrate/results/processed_data/psth_data_128fibers.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading BOTH Model Data ===\n",
      "\n",
      "Loading Cochlea data...\n",
      "Loading cochlea PSTH data from: /home/ekim/PycharmProjects/phd_firstyear/subcorticalSTRF/cochlea_meanrate/out/condition_psths/cochlea_psths.mat\n",
      "✓ Cochlea PSTH data loaded successfully\n",
      "Parameters extracted:\n",
      "  CFs: 20 values\n",
      "  Frequencies: 20 values\n",
      "  dB levels: [50. 60. 70. 80.]\n",
      "\n",
      "Loading BEZ data...\n",
      "Loading BEZ PSTH data from: //subcorticalSTRF/BEZ2018_meanrate/results/processed_data/psth_data_128fibers.mat\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '//subcorticalSTRF/BEZ2018_meanrate/results/processed_data/psth_data_128fibers.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/phd_firstyear/.venv/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:39\u001b[39m, in \u001b[36m_open_file\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '//subcorticalSTRF/BEZ2018_meanrate/results/processed_data/psth_data_128fibers.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m cochlea_data, cochlea_params = load_cochlea_psth_data()\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLoading BEZ data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m bez_data, bez_params = \u001b[43mload_bez_psth_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Combine into single structure\u001b[39;00m\n\u001b[32m     19\u001b[39m model_data = {\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcochlea\u001b[39m\u001b[33m'\u001b[39m: cochlea_data,\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbez\u001b[39m\u001b[33m'\u001b[39m: bez_data\n\u001b[32m     22\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/phd_firstyear/subcorticalSTRF/convolution_HRF/convolutionHRF_bez_eachrun_231025.py:40\u001b[39m, in \u001b[36mload_bez_psth_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     37\u001b[39m bez_file = bez_dir / \u001b[33m'\u001b[39m\u001b[33mpsth_data_128fibers.mat\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading BEZ PSTH data from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbez_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m bez_data = \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbez_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_as_record\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ BEZ PSTH data loaded successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Extract parameters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/phd_firstyear/.venv/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:233\u001b[39m, in \u001b[36mloadmat\u001b[39m\u001b[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03mLoad MATLAB file.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m \u001b[33;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m variable_names = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mvariable_names\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatfile_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/phd_firstyear/.venv/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:17\u001b[39m, in \u001b[36m_open_file_context\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_context\u001b[39m(file_like, appendmat, mode=\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     f, opened = \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/phd_firstyear/.venv/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:45\u001b[39m, in \u001b[36m_open_file\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like.endswith(\u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     44\u001b[39m         file_like += \u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m     48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mReader needs file name or open file-like object\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     49\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '//subcorticalSTRF/BEZ2018_meanrate/results/processed_data/psth_data_128fibers.mat'"
     ]
    }
   ],
   "source": [
    "# Load data based on model selection\n",
    "print(f\"=== Loading {MODEL.upper()} Model Data ===\\n\")\n",
    "\n",
    "if MODEL == 'cochlea':\n",
    "    model_data, full_parameters = load_cochlea_psth_data()\n",
    "    \n",
    "elif MODEL == 'bez':\n",
    "    # Use the per-run BEZ loader\n",
    "    model_data, full_parameters = load_bez_psth_data()\n",
    "    \n",
    "elif MODEL == 'both':\n",
    "    print(\"Loading Cochlea data...\")\n",
    "    cochlea_data, cochlea_params = load_cochlea_psth_data()\n",
    "    \n",
    "    print(\"\\nLoading BEZ data...\")\n",
    "    bez_data, bez_params = load_bez_psth_data()\n",
    "    \n",
    "    # Combine into single structure\n",
    "    model_data = {\n",
    "        'cochlea': cochlea_data,\n",
    "        'bez': bez_data\n",
    "    }\n",
    "    \n",
    "    # Parameters should be the same for both\n",
    "    full_parameters = cochlea_params\n",
    "    \n",
    "    print(\"\\n✓ Both models loaded successfully!\")\n",
    "else:\n",
    "    raise ValueError(f\"Invalid model: {MODEL}\")\n",
    "\n",
    "if MODEL != 'both':\n",
    "    print(\"\\n✓ Data loaded successfully!\")\n",
    "    print(f\"\\nFull parameter space:\")\n",
    "    print(f\"  CFs: {len(full_parameters['cfs'])} values\")\n",
    "    print(f\"  Frequencies: {len(full_parameters['frequencies'])} values\")\n",
    "    print(f\"  dB levels: {full_parameters['dbs']}\")\n",
    "    \n",
    "    if MODEL == 'bez':\n",
    "        # Check number of runs\n",
    "        sample_data = model_data['hsr_all']\n",
    "        n_runs = sample_data.shape[3]\n",
    "        print(f\"  Runs per condition: {n_runs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6d846",
   "metadata": {},
   "source": [
    "## Step 3: Create Data Subset (Optional)\n",
    "\n",
    "Create a subset of the full parameter space for faster processing during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create argument-like object for subset_parameters function\n",
    "class SubsetArgs:\n",
    "    def __init__(self):\n",
    "        self.test = TEST_MODE\n",
    "        self.max_cfs = MAX_CFS\n",
    "        self.max_freqs = MAX_FREQS\n",
    "        self.max_dbs = MAX_DBS\n",
    "\n",
    "args = SubsetArgs()\n",
    "parameters, indices = subset_parameters(full_parameters, args)\n",
    "\n",
    "print(\"=== Data Subset Configuration ===\")\n",
    "print(f\"Processing:\")\n",
    "print(f\"  CFs: {len(parameters['cfs'])}/{len(full_parameters['cfs'])}\")\n",
    "print(f\"  Frequencies: {len(parameters['frequencies'])}/{len(full_parameters['frequencies'])}\")\n",
    "print(f\"  dB levels: {len(parameters['dbs'])}/{len(full_parameters['dbs'])}\")\n",
    "print(f\"\\nFirst few CFs: {parameters['cfs'][:5]}\")\n",
    "print(f\"First few frequencies: {parameters['frequencies'][:5]}\")\n",
    "print(f\"dB levels: {parameters['dbs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777f229",
   "metadata": {},
   "source": [
    "## Step 4: Generate and Visualize Canonical HRF\n",
    "\n",
    "Create the canonical hemodynamic response function that will be used for convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate canonical HRF\n",
    "print(\"=== Generating Canonical HRF ===\\n\")\n",
    "hrf, time_points = generate_canonical_hrf(tr=TR, time_length=HRF_LENGTH)\n",
    "\n",
    "print(f\"HRF parameters:\")\n",
    "print(f\"  Duration: {HRF_LENGTH}s\")\n",
    "print(f\"  Sampling rate: {1/TR:.0f} Hz ({TR*1000:.1f} ms per sample)\")\n",
    "print(f\"  Number of samples: {len(hrf)}\")\n",
    "print(f\"  Peak time: ~{time_points[np.argmax(hrf)]:.1f}s\")\n",
    "\n",
    "# Plot the HRF\n",
    "timestamp = generate_timestamp() if SAVE_PLOTS else None\n",
    "plot_hrf(\n",
    "    hrf, \n",
    "    time_points, \n",
    "    save_plots=SAVE_PLOTS,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    timestamp=timestamp,\n",
    "    plot_format=PLOT_FORMAT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d9e3c",
   "metadata": {},
   "source": [
    "## Step 5: Run HRF Convolution\n",
    "\n",
    "Convolve the PSTH data with the canonical HRF.\n",
    "\n",
    "**Important Difference:**\n",
    "- **Cochlea**: Convolves single response per condition\n",
    "- **BEZ**: Convolves each simulation run separately (preserves variability)\n",
    "\n",
    "**Note:** This step may take several minutes depending on the data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run convolution based on model\n",
    "print(f\"=== Running HRF Convolution for {MODEL.upper()} ===\\n\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "if MODEL == 'cochlea':\n",
    "    # Standard convolution for Cochlea\n",
    "    convolved_responses, hrf_used, time_axis = convolve_cochlea_with_hrf(\n",
    "        model_data, \n",
    "        parameters, \n",
    "        indices, \n",
    "        FIBER_TYPES,\n",
    "        tr=TR, \n",
    "        hrf_length=HRF_LENGTH\n",
    "    )\n",
    "    \n",
    "elif MODEL == 'bez':\n",
    "    # Per-run convolution for BEZ (preserves run variability)\n",
    "    print(\"Processing each BEZ run separately...\")\n",
    "    convolved_responses, hrf_used, time_points = convolve_bez_runs_with_hrf(\n",
    "        model_data,\n",
    "        parameters,\n",
    "        fiber_types=FIBER_TYPES,\n",
    "        tr=TR,\n",
    "        hrf_length=HRF_LENGTH\n",
    "    )\n",
    "    time_axis = time_points\n",
    "    \n",
    "elif MODEL == 'both':\n",
    "    print(\"Processing Cochlea model...\")\n",
    "    cochlea_convolved, hrf_used, time_axis = convolve_cochlea_with_hrf(\n",
    "        model_data['cochlea'],\n",
    "        parameters,\n",
    "        indices,\n",
    "        FIBER_TYPES,\n",
    "        tr=TR,\n",
    "        hrf_length=HRF_LENGTH\n",
    "    )\n",
    "    \n",
    "    print(\"\\nProcessing BEZ model (each run separately)...\")\n",
    "    bez_convolved, _, _ = convolve_bez_runs_with_hrf(\n",
    "        model_data['bez'],\n",
    "        parameters,\n",
    "        fiber_types=FIBER_TYPES,\n",
    "        tr=TR,\n",
    "        hrf_length=HRF_LENGTH\n",
    "    )\n",
    "    \n",
    "    # Combine results\n",
    "    convolved_responses = {\n",
    "        'cochlea': cochlea_convolved,\n",
    "        'bez': bez_convolved\n",
    "    }\n",
    "\n",
    "print(\"\\n✓ Convolution complete!\")\n",
    "print(f\"\\nConvolved response structure:\")\n",
    "if MODEL == 'both':\n",
    "    print(f\"  Models: {list(convolved_responses.keys())}\")\n",
    "    print(f\"  Cochlea fiber types: {list(convolved_responses['cochlea'].keys())}\")\n",
    "    print(f\"  BEZ fiber types: {list(convolved_responses['bez'].keys())}\")\n",
    "elif MODEL == 'bez':\n",
    "    print(f\"  Fiber types: {list(convolved_responses.keys())}\")\n",
    "    print(f\"  Structure: [fiber_type][CF][frequency][dB][run_idx]\")\n",
    "else:\n",
    "    print(f\"  Fiber types: {list(convolved_responses.keys())}\")\n",
    "    print(f\"  Structure: [fiber_type][CF][frequency][dB]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a14ee",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Convolved Responses\n",
    "\n",
    "Plot the HRF-convolved responses for each fiber type.\n",
    "\n",
    "**Plotting Options:**\n",
    "- **Cochlea**: Shows single response trace per condition\n",
    "- **BEZ**: Shows individual runs + mean ± SEM across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10245989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convolved responses\n",
    "print(\"=== Plotting Convolved Responses ===\\n\")\n",
    "\n",
    "timestamp = generate_timestamp() if SAVE_PLOTS else None\n",
    "\n",
    "if MODEL == 'cochlea':\n",
    "    # Standard plotting for Cochlea\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses:\n",
    "            print(f\"Plotting {fiber_type.upper()} fibers...\")\n",
    "            plot_convolved_responses(\n",
    "                convolved_responses,\n",
    "                parameters,\n",
    "                fiber_type=fiber_type,\n",
    "                db_val=DB_LEVEL_TO_PLOT,\n",
    "                model_name='COCHLEA',\n",
    "                save_plots=SAVE_PLOTS,\n",
    "                output_dir=OUTPUT_DIR,\n",
    "                timestamp=timestamp,\n",
    "                plot_format=PLOT_FORMAT\n",
    "            )\n",
    "\n",
    "elif MODEL == 'bez':\n",
    "    # Per-run plotting for BEZ\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses:\n",
    "            print(f\"\\nPlotting {fiber_type.upper()} fibers...\")\n",
    "            \n",
    "            # Plot 1: Individual runs + mean/SEM for first CF\n",
    "            print(f\"  - Individual runs + mean/SEM...\")\n",
    "            plot_convolved_runs(\n",
    "                convolved_responses,\n",
    "                parameters,\n",
    "                fiber_type=fiber_type,\n",
    "                db_val=DB_LEVEL_TO_PLOT,\n",
    "                tr=TR,\n",
    "                plot_individual_runs=True,\n",
    "                plot_mean_and_sem=True,\n",
    "                max_runs_display=10,  # Show max 10 individual runs\n",
    "                save_plots=SAVE_PLOTS,\n",
    "                output_dir=OUTPUT_DIR,\n",
    "                timestamp=timestamp,\n",
    "                plot_format=PLOT_FORMAT\n",
    "            )\n",
    "            \n",
    "            # Plot 2: Comparison across multiple CFs\n",
    "            print(f\"  - Comparison across CFs...\")\n",
    "            plot_runs_comparison_across_cfs(\n",
    "                convolved_responses,\n",
    "                parameters,\n",
    "                fiber_type=fiber_type,\n",
    "                db_val=DB_LEVEL_TO_PLOT,\n",
    "                tr=TR,\n",
    "                max_cfs=6,\n",
    "                save_plots=SAVE_PLOTS,\n",
    "                output_dir=OUTPUT_DIR,\n",
    "                timestamp=timestamp,\n",
    "                plot_format=PLOT_FORMAT\n",
    "            )\n",
    "\n",
    "elif MODEL == 'both':\n",
    "    # Plot both models\n",
    "    print(\"\\nPlotting Cochlea model...\")\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses['cochlea']:\n",
    "            plot_convolved_responses(\n",
    "                convolved_responses['cochlea'],\n",
    "                parameters,\n",
    "                fiber_type=fiber_type,\n",
    "                db_val=DB_LEVEL_TO_PLOT,\n",
    "                model_name='COCHLEA',\n",
    "                save_plots=SAVE_PLOTS,\n",
    "                output_dir=OUTPUT_DIR,\n",
    "                timestamp=timestamp,\n",
    "                plot_format=PLOT_FORMAT\n",
    "            )\n",
    "    \n",
    "    print(\"\\nPlotting BEZ model (with runs)...\")\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses['bez']:\n",
    "            plot_convolved_runs(\n",
    "                convolved_responses['bez'],\n",
    "                parameters,\n",
    "                fiber_type=fiber_type,\n",
    "                db_val=DB_LEVEL_TO_PLOT,\n",
    "                tr=TR,\n",
    "                save_plots=SAVE_PLOTS,\n",
    "                output_dir=OUTPUT_DIR,\n",
    "                timestamp=timestamp,\n",
    "                plot_format=PLOT_FORMAT\n",
    "            )\n",
    "\n",
    "print(\"\\n✓ Plotting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de825d6",
   "metadata": {},
   "source": [
    "## Step 7: Save Convolved Data\n",
    "\n",
    "Save the convolved responses to pickle files for later use.\n",
    "\n",
    "**File Naming:**\n",
    "- **Cochlea**: `COCHLEA_convolved_responses_{fiber_type}_{timestamp}.pkl`\n",
    "- **BEZ**: `BEZ_convolved_responses_{fiber_type}_{timestamp}.pkl`\n",
    "\n",
    "**Important:** BEZ files contain all runs separately for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save convolved data\n",
    "if SAVE_DATA:\n",
    "    print(\"=== Saving Convolved Responses ===\\n\")\n",
    "    \n",
    "    timestamp = generate_timestamp()\n",
    "    \n",
    "    if MODEL == 'both':\n",
    "        # Save each model separately\n",
    "        print(\"Saving Cochlea results...\")\n",
    "        cochlea_output_dir = Path(OUTPUT_DIR) / 'cochlea'\n",
    "        save_convolved_data(\n",
    "            convolved_responses['cochlea'],\n",
    "            str(cochlea_output_dir),\n",
    "            timestamp,\n",
    "            model_name='COCHLEA'\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSaving BEZ results (with all runs)...\")\n",
    "        bez_output_dir = Path(OUTPUT_DIR) / 'bez'\n",
    "        save_convolved_data(\n",
    "            convolved_responses['bez'],\n",
    "            str(bez_output_dir),\n",
    "            timestamp,\n",
    "            model_name='BEZ'\n",
    "        )\n",
    "        \n",
    "        # Also save combined results\n",
    "        combined_file = (\n",
    "            Path(OUTPUT_DIR) / \n",
    "            f\"combined_models_results_{timestamp}.pkl\"\n",
    "        )\n",
    "        print(f\"\\nSaving combined results to: {combined_file}\")\n",
    "        with open(combined_file, 'wb') as f:\n",
    "            pickle.dump(convolved_responses, f)\n",
    "        print(f\"✓ Combined data saved\")\n",
    "        \n",
    "    else:\n",
    "        # Save single model\n",
    "        print(f\"Saving {MODEL.upper()} results to: {OUTPUT_DIR}\")\n",
    "        save_convolved_data(\n",
    "            convolved_responses,\n",
    "            OUTPUT_DIR,\n",
    "            timestamp,\n",
    "            model_name=MODEL.upper()\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n✓ All data saved successfully!\")\n",
    "    print(f\"Timestamp: {timestamp}\")\n",
    "else:\n",
    "    print(\"Data saving skipped (SAVE_DATA=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314972e6",
   "metadata": {},
   "source": [
    "## Step 8: Inspect Results\n",
    "\n",
    "Quick inspection of the convolved data structure and sample responses.\n",
    "\n",
    "**Key Difference:**\n",
    "- **Cochlea**: Single array per condition\n",
    "- **BEZ**: Dictionary of arrays (one per run) per condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect convolved data structure\n",
    "print(\"=== Data Structure Inspection ===\\n\")\n",
    "\n",
    "if MODEL == 'both':\n",
    "    # Inspect Cochlea\n",
    "    print(\"COCHLEA Model:\")\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses['cochlea']:\n",
    "            fiber_data = convolved_responses['cochlea'][fiber_type]\n",
    "            n_cfs = len(fiber_data)\n",
    "            sample_cf = list(fiber_data.keys())[0]\n",
    "            n_freqs = len(fiber_data[sample_cf])\n",
    "            sample_freq = list(fiber_data[sample_cf].keys())[0]\n",
    "            n_dbs = len(fiber_data[sample_freq][sample_freq])\n",
    "            sample_db = list(fiber_data[sample_freq][sample_freq].keys())[0]\n",
    "            sample_response = fiber_data[sample_freq][sample_freq][sample_db]\n",
    "            \n",
    "            print(f\"  {fiber_type.upper()}:\")\n",
    "            print(f\"    CFs: {n_cfs}\")\n",
    "            print(f\"    Frequencies per CF: {n_freqs}\")\n",
    "            print(f\"    dB levels: {n_dbs}\")\n",
    "            print(f\"    Sample response: {len(sample_response)} samples\")\n",
    "            print(f\"    Duration: {len(sample_response) * TR:.1f}s\")\n",
    "    \n",
    "    # Inspect BEZ\n",
    "    print(\"\\nBEZ Model (with runs):\")\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses['bez']:\n",
    "            fiber_data = convolved_responses['bez'][fiber_type]\n",
    "            n_cfs = len(fiber_data)\n",
    "            sample_cf = list(fiber_data.keys())[0]\n",
    "            n_freqs = len(fiber_data[sample_cf])\n",
    "            sample_freq = list(fiber_data[sample_cf].keys())[0]\n",
    "            n_dbs = len(fiber_data[sample_freq][sample_freq])\n",
    "            sample_db = list(fiber_data[sample_freq][sample_freq].keys())[0]\n",
    "            sample_runs = fiber_data[sample_freq][sample_freq][sample_db]\n",
    "            \n",
    "            # Count runs\n",
    "            n_runs = len([r for r in sample_runs.values() if r is not None])\n",
    "            sample_run = next(\n",
    "                (r for r in sample_runs.values() if r is not None), \n",
    "                None\n",
    "            )\n",
    "            \n",
    "            print(f\"  {fiber_type.upper()}:\")\n",
    "            print(f\"    CFs: {n_cfs}\")\n",
    "            print(f\"    Frequencies per CF: {n_freqs}\")\n",
    "            print(f\"    dB levels: {n_dbs}\")\n",
    "            print(f\"    Runs per condition: {n_runs}\")\n",
    "            if sample_run is not None:\n",
    "                print(f\"    Sample run length: {len(sample_run)} samples\")\n",
    "                print(f\"    Duration: {len(sample_run) * TR:.1f}s\")\n",
    "\n",
    "elif MODEL == 'bez':\n",
    "    for fiber_type in FIBER_TYPES:\n",
    "        if fiber_type in convolved_responses:\n",
    "            fiber_data = convolved_responses[fiber_type]\n",
    "            # ...existing inspection for BEZ...\n",
    "            sample_cf = list(fiber_data.keys())[0]\n",
    "            sample_freq = list(fiber_data[sample_cf].keys())[0]\n",
    "            sample_db = list(fiber_data[sample_cf][sample_freq].keys())[0]\n",
    "            sample_runs = fiber_data[sample_cf][sample_freq][sample_db]\n",
    "            \n",
    "            n_runs = len([r for r in sample_runs.values() if r is not None])\n",
    "            sample_run = next(\n",
    "                (r for r in sample_runs.values() if r is not None), \n",
    "                None\n",
    "            )\n",
    "            \n",
    "            print(f\"{fiber_type.upper()}:\")\n",
    "            print(f\"  Structure: [CF][frequency][dB][run_idx]\")\n",
    "            print(f\"  Runs per condition: {n_runs}\")\n",
    "            if sample_run is not None:\n",
    "                print(f\"  Sample run: {len(sample_run)} samples \" \n",
    "                      f\"({len(sample_run) * TR:.1f}s)\")\n",
    "else:\n",
    "    # Cochlea only\n",
    "    # ...existing code for cochlea...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfcdd1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The HRF convolution analysis is complete! \n",
    "\n",
    "### What was done:\n",
    "1. ✓ Loaded PSTH data from selected model(s)\n",
    "2. ✓ Generated canonical HRF\n",
    "3. ✓ Convolved PSTH data with HRF\n",
    "   - **Cochlea**: Single response per condition\n",
    "   - **BEZ**: Each simulation run processed separately\n",
    "4. ✓ Visualized results\n",
    "5. ✓ Saved convolved responses\n",
    "\n",
    "### Key Differences Between Models:\n",
    "- **Cochlea**: Deterministic model - single response per condition\n",
    "- **BEZ**: Stochastic model - multiple runs per condition (preserves variability)\n",
    "\n",
    "### Data Structure:\n",
    "```\n",
    "Cochlea: [fiber_type][CF][frequency][dB] → single_array\n",
    "BEZ:     [fiber_type][CF][frequency][dB][run_idx] → run_array\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "- Extract specific dB levels using `test_extract_db_utility.ipynb`\n",
    "- Run correlation analysis using `test_correlation_analysis.ipynb`\n",
    "- Compare within-BEZ variability vs Cochlea-BEZ differences\n",
    "\n",
    "### Files Generated:\n",
    "Check the `results/` directory for:\n",
    "- `BEZ_convolved_responses_{fiber_type}_{timestamp}.pkl` (with all runs)\n",
    "- `COCHLEA_convolved_responses_{fiber_type}_{timestamp}.pkl`\n",
    "- Plots (if enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59379740",
   "metadata": {},
   "source": [
    "## Diagnostic: Check PSTH Temporal Resolution\n",
    "\n",
    "Before running convolution, let's verify the actual temporal resolution of the PSTH data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b14792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for clues about PSTH temporal resolution\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== Searching for PSTH Temporal Resolution Clues ===\\n\")\n",
    "\n",
    "# 1. Check MATLAB files for 'dt' or 'fs' or 'sampling' parameters\n",
    "search_dir = Path.cwd().parent\n",
    "print(f\"Searching in: {search_dir}\\n\")\n",
    "\n",
    "# Search patterns\n",
    "patterns = [\n",
    "    (\"BEZ scripts\", \"BEZ*.py\", [\"dt\", \"fs\", \"sampling_rate\", \"time_step\"]),\n",
    "    (\"Cochlea scripts\", \"*cochlea*.py\", [\"dt\", \"fs\", \"sampling\"]),\n",
    "    (\"MATLAB files\", \"*.m\", [\"dt\", \"fs\", \"Fs\"]),\n",
    "]\n",
    "\n",
    "for desc, file_pattern, search_terms in patterns:\n",
    "    print(f\"\\n{desc} ({file_pattern}):\")\n",
    "    files = list(search_dir.rglob(file_pattern))[:5]  # First 5 matches\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            content = file.read_text()\n",
    "            for term in search_terms:\n",
    "                if term in content:\n",
    "                    # Find lines containing the term\n",
    "                    lines = [\n",
    "                        line.strip() for line in content.split('\\n') \n",
    "                        if term in line\n",
    "                    ][:3]  # First 3 matches\n",
    "                    if lines:\n",
    "                        print(f\"\\n  {file.name}:\")\n",
    "                        for line in lines:\n",
    "                            print(f\"    {line}\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# 2. Check actual PSTH data structure\n",
    "print(\"\\n\\n=== Checking Actual PSTH Data ===\")\n",
    "\n",
    "# Try loading a small sample\n",
    "try:\n",
    "    from scipy.io import loadmat\n",
    "    \n",
    "    # Try BEZ data\n",
    "    bez_paths = [\n",
    "        Path('/home/ekim/PycharmProjects/phd_firstyear/subcorticalSTRF/BEZ2018_meanrate/results/processed_data/psth_data_128fibers.mat'),\n",
    "        Path('/home/ekim/audio_periph_models/BEZ2018a_model/results/processed_data/psth_data_128fibers.mat'),\n",
    "    ]\n",
    "    \n",
    "    for bez_path in bez_paths:\n",
    "        if bez_path.exists():\n",
    "            print(f\"\\nLoading: {bez_path.name}\")\n",
    "            data = loadmat(str(bez_path), struct_as_record=False)\n",
    "            \n",
    "            # Check for timing information\n",
    "            print(\"  Available fields:\")\n",
    "            for key in data.keys():\n",
    "                if not key.startswith('__'):\n",
    "                    print(f\"    - {key}\")\n",
    "            \n",
    "            # Check PSTH length\n",
    "            if 'hsr_all' in data:\n",
    "                sample = data['hsr_all']\n",
    "                print(f\"\\n  PSTH data shape: {sample.shape}\")\n",
    "                print(f\"  Likely dimensions: [n_CFs, n_freqs, n_dBs, n_runs]\")\n",
    "                \n",
    "                # Get one PSTH\n",
    "                psth_sample = sample[0, 0, 0, 0]\n",
    "                if hasattr(psth_sample, 'flatten'):\n",
    "                    psth_array = psth_sample.flatten()\n",
    "                else:\n",
    "                    psth_array = np.array(psth_sample)\n",
    "                \n",
    "                print(f\"\\n  Sample PSTH:\")\n",
    "                print(f\"    Length: {len(psth_array)} samples\")\n",
    "                print(f\"    If 200ms stimulus:\")\n",
    "                print(f\"      @ 1000 Hz (1ms): {len(psth_array)} samples = {len(psth_array)}ms\")\n",
    "                print(f\"      @ 10000 Hz (0.1ms): {len(psth_array)} samples = {len(psth_array)/10}ms\")\n",
    "                print(f\"      @ 100 Hz (10ms): {len(psth_array)} samples = {len(psth_array)*10}ms\")\n",
    "            \n",
    "            break\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "print(\"\\n\\n=== Conclusion ===\")\n",
    "print(\"Based on the PSTH length, determine which makes sense:\")\n",
    "print(\"  - 200 samples @ 1ms = 200ms stimulus ✓ (most likely)\")\n",
    "print(\"  - 2000 samples @ 0.1ms = 200ms stimulus\")\n",
    "print(\"  - 20 samples @ 10ms = 200ms stimulus\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
